services:

  kafka:
    image: apache/kafka:latest
    container_name: kafka
    ports:
      - '9092:9092'
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT_HOST://localhost:9092,PLAINTEXT://kafka:19092'
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka:29093'
      KAFKA_LISTENERS: 'CONTROLLER://:29093,PLAINTEXT_HOST://:9092,PLAINTEXT://:19092'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      CLUSTER_ID: '4L6g3nShT-eMCtK--X86sw'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_NUM_PARTITIONS: 3

  kafka-init:
    image: apache/kafka:latest
    depends_on:
      - kafka
    command: [ "bash", "./create-topic.sh" ]
    working_dir: /scripts
    volumes:
      - ./scripts:/scripts

  postgres:
    image: postgres:latest
    restart: always
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    ports:
      - '5432:5432'
    volumes:
      # copy the sql script to create tables
      - ./sql/create_table.sql:/docker-entrypoint-initdb.d/create_table.sql

  kafka-to-dwh:
    image: fsilberstein/kafka-to-dwh:latest
    depends_on:
      - kafka
      - postgres
    entrypoint: [ "python",
                  "main.py",
                  "--runner=DirectRunner",
                  "--dev=true",
                  "--broker=kafka:19092",
                  "--pg-host=postgres",
                  "--streaming" ]

# -------------------------------------------
#  I cannot make it work with Flink in docker-compose
## -------------------------------------------

#  jobmanager:
#    image: flink:1.18-scala_2.12
#    ports:
#      - "8081:8081"
#    command: jobmanager
#    environment:
#      - |
#        FLINK_PROPERTIES=
#        jobmanager.rpc.address: jobmanager
#
#  taskmanager:
#    image: flink:1.18-scala_2.12
#    depends_on:
#      - jobmanager
#    command: taskmanager
#    scale: 1
#    environment:
#      FLINK_PROPERTIES: "jobmanager.rpc.address: jobmanager\ntaskmanager.numberOfTaskSlots: 2"
#      # Because Docker on Mac does not support host network sharing, we need these env vars to communicate with the externally
#      # running python worker. When the Task Manager opens connections for the python worker it will 1) use `host.docker.internal`
#      # instead of `localhost` 2) use ports 8100-8200 in a round-robin fashion.
#      BEAM_WORKER_POOL_IN_DOCKER_VM: 1
#      DOCKER_MAC_CONTAINER: 1
#
#  kafka-to-dwh:
#    image: fsilberstein/kafka-to-dwh:latest
#    depends_on:
#      - kafka
#      - postgres
#      - jobmanager
#    environment:
#      - KAFKA_BROKER=kafka:19092
#      - KAFKA_TOPIC=companies
#    entrypoint: [ "python",
#                  "main.py",
#                  "--runner=FlinkRunner",
#                  "--flink_master=jobmanager:8081",
#                  "--broker=kafka:19092",
#                  "--environment_type=EXTERNAL",
#                  "--environment_config=localhost:50000",
#                  "--streaming" ]